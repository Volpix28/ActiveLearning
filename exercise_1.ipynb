{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, SubsetRandomSampler\n",
    "from sklearn.metrics import accuracy_score, pairwise_distances\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl geladener Bilder: 25000\n",
      "Form eines Bildes: (64, 64)\n",
      "Erste 5 Labels: [1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_image(image_path, size=(64, 64)):\n",
    "    \"\"\"\n",
    "    Lädt ein Bild von einem gegebenen Pfad, ändert dessen Größe und konvertiert es in Graustufen.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize(size).convert('L')\n",
    "    image_array = np.array(image) / 255.0\n",
    "    \n",
    "    return image_array\n",
    "\n",
    "def load_and_preprocess_images(directory, csv_path, size=(64, 64)):\n",
    "    \"\"\"\n",
    "    Lädt und verarbeitet alle Bilder in einem Verzeichnis basierend auf einer CSV-Datei, die Labels enthält.\n",
    "    \"\"\"\n",
    "    # CSV-Datei laden, die Labels und Bildpfade enthält\n",
    "    labels_df = pd.read_csv(csv_path)\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        if os.path.isfile(file_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "\n",
    "            image_array = load_and_preprocess_image(file_path, size)\n",
    "            images.append(image_array)\n",
    "            # Das Label aus der CSV-Datei extrahieren\n",
    "            label = labels_df[labels_df['image'] == filename]['labels'].values[0]\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "directory = 'dataset/cat_dog'\n",
    "csv_path = 'dataset/cat_dog.csv'\n",
    "\n",
    "images, labels = load_and_preprocess_images(directory, csv_path)\n",
    "\n",
    "print(f\"Anzahl geladener Bilder: {len(images)}\")\n",
    "print(f\"Form eines Bildes: {images[0].shape}\")\n",
    "print(f\"Erste 5 Labels: {labels[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition (simple cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=8192, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)  # 16 Filter, Kernel-Größe 3\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1) # 32 Filter, Kernel-Größe 3\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 128)      # Vollverbundene Schicht\n",
    "        self.fc2 = nn.Linear(128, 2)                 # Ausgangsschicht\n",
    "        self.pool = nn.MaxPool2d(2, 2)               # Pooling-Schicht\n",
    "        self.relu = nn.ReLU()                        # ReLU Aktivierungsfunktion\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 16 * 16)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufteilung der Daten und Umwandlung in Tensoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Trainingsdaten: 5625\n",
      "Anzahl Testdaten: 625\n",
      "Anzahl 'ungelabelter' Daten: 18750\n"
     ]
    }
   ],
   "source": [
    "tensor_images = torch.tensor(images).float()\n",
    "tensor_labels = torch.tensor(labels).long()\n",
    "\n",
    "total_count = len(tensor_labels)\n",
    "\n",
    "num_labeled = int(0.25 * total_count)\n",
    "num_test = int(0.1 * num_labeled)\n",
    "\n",
    "# Indizes mischen und aufteilen\n",
    "indices = torch.randperm(total_count)\n",
    "labeled_indices = indices[:num_labeled]\n",
    "test_indices = labeled_indices[:num_test]  # Testindizes von den gelabelten Indizes nehmen\n",
    "train_indices = labeled_indices[num_test:]  # Restliche gelabelte Daten für Training\n",
    "unlabeled_indices = indices[num_labeled:]\n",
    "\n",
    "# Erstellen von Datenladern\n",
    "test_dataset = TensorDataset(tensor_images[test_indices], tensor_labels[test_indices])\n",
    "train_dataset = TensorDataset(tensor_images[train_indices], tensor_labels[train_indices])\n",
    "# unlabeled_dataset = TensorDataset(tensor_images[unlabeled_indices], torch.zeros(len(unlabeled_indices))) # Keine Labels für ungelabelte Daten -> für manuelles Labeln\n",
    "unlabeled_dataset = TensorDataset(tensor_images[unlabeled_indices], tensor_labels[unlabeled_indices]) # Für simulation des human-in-the-loop\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f\"Anzahl Trainingsdaten: {len(train_loader.dataset)}\")\n",
    "print(f\"Anzahl Testdaten: {len(test_loader.dataset)}\")\n",
    "print(f\"Anzahl 'ungelabelter' Daten: {len(unlabeled_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiales Training als Vergleichsbasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 88/88 [00:06<00:00, 13.91it/s, loss=0.691]\n",
      "Epoch 2: 100%|██████████| 88/88 [00:06<00:00, 14.52it/s, loss=0.668]\n",
      "Epoch 3: 100%|██████████| 88/88 [00:06<00:00, 13.88it/s, loss=0.586]\n",
      "Epoch 4: 100%|██████████| 88/88 [00:06<00:00, 13.19it/s, loss=0.609]\n",
      "Epoch 5: 100%|██████████| 88/88 [00:06<00:00, 14.11it/s, loss=0.59] \n",
      "Epoch 6: 100%|██████████| 88/88 [00:06<00:00, 14.44it/s, loss=0.562]\n",
      "Epoch 7: 100%|██████████| 88/88 [00:06<00:00, 14.44it/s, loss=0.556]\n",
      "Epoch 8: 100%|██████████| 88/88 [00:06<00:00, 14.57it/s, loss=0.632]\n",
      "Epoch 9: 100%|██████████| 88/88 [00:06<00:00, 14.28it/s, loss=0.566]\n",
      "Epoch 10: 100%|██████████| 88/88 [00:05<00:00, 14.67it/s, loss=0.406]\n",
      "Epoch 11: 100%|██████████| 88/88 [00:06<00:00, 14.23it/s, loss=0.301]\n",
      "Epoch 12: 100%|██████████| 88/88 [00:06<00:00, 14.34it/s, loss=0.405]\n",
      "Epoch 13: 100%|██████████| 88/88 [00:06<00:00, 13.52it/s, loss=0.29] \n",
      "Epoch 14: 100%|██████████| 88/88 [00:06<00:00, 14.28it/s, loss=0.146]\n",
      "Epoch 15: 100%|██████████| 88/88 [00:06<00:00, 14.11it/s, loss=0.139] \n",
      "Epoch 16: 100%|██████████| 88/88 [00:06<00:00, 14.22it/s, loss=0.134] \n",
      "Epoch 17: 100%|██████████| 88/88 [00:06<00:00, 14.14it/s, loss=0.0678]\n",
      "Epoch 18: 100%|██████████| 88/88 [00:06<00:00, 14.34it/s, loss=0.0507]\n",
      "Epoch 19: 100%|██████████| 88/88 [00:05<00:00, 14.76it/s, loss=0.02]  \n",
      "Epoch 20: 100%|██████████| 88/88 [00:06<00:00, 14.54it/s, loss=0.0321] \n"
     ]
    }
   ],
   "source": [
    "def train(model, data_loader, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        for images, labels in progress_bar:\n",
    "            # Format (batch_size, channels, width, height)\n",
    "            images = images.unsqueeze(1)  # Dimension für den Kanal\n",
    "            \n",
    "            # Feed Forward\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backprop.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "train(model, train_loader, criterion, optimizer, epochs=20)\n",
    "torch.save(model.state_dict(), 'init_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit auf Testdaten: 0.6928\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.unsqueeze(1)  # Dimension für den Kanal hinzufügen\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted.numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    return accuracy\n",
    "\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Genauigkeit auf Testdaten: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty Sampling\n",
    "\n",
    "gewählte Methoden \n",
    "\n",
    "1. Entropie \n",
    "2. Lowest Confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 14.28it/s, loss=0.601]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 14.74it/s, loss=0.681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Genauigkeit auf Testdaten: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 14.70it/s, loss=0.645]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 14.23it/s, loss=0.616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, Genauigkeit auf Testdaten: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 14.14it/s, loss=0.47] \n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 14.05it/s, loss=0.521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, Genauigkeit auf Testdaten: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:05<00:00, 14.90it/s, loss=0.465]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 13.24it/s, loss=0.647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, Genauigkeit auf Testdaten: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 14.71it/s, loss=0.403]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 14.35it/s, loss=0.435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, Genauigkeit auf Testdaten: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 13.53it/s, loss=0.465]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 13.01it/s, loss=0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, Genauigkeit auf Testdaten: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 14.55it/s, loss=0.25] \n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 14.36it/s, loss=0.27] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, Genauigkeit auf Testdaten: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 13.95it/s, loss=0.316]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 14.22it/s, loss=0.2]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, Genauigkeit auf Testdaten: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 14.45it/s, loss=0.161]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 14.45it/s, loss=0.206] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, Genauigkeit auf Testdaten: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 13.96it/s, loss=0.123] \n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 14.06it/s, loss=0.0934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, Genauigkeit auf Testdaten: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 13.54it/s, loss=0.693]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:08<00:00, 10.43it/s, loss=0.637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Genauigkeit auf Testdaten: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:08<00:00, 10.89it/s, loss=0.579]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:05<00:00, 14.95it/s, loss=0.45] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, Genauigkeit auf Testdaten: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 13.59it/s, loss=0.569]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 14.64it/s, loss=0.478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, Genauigkeit auf Testdaten: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 14.23it/s, loss=0.41] \n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 13.88it/s, loss=0.446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, Genauigkeit auf Testdaten: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:05<00:00, 14.84it/s, loss=0.321]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:05<00:00, 15.05it/s, loss=0.26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, Genauigkeit auf Testdaten: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 14.33it/s, loss=0.213]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 14.23it/s, loss=0.0678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, Genauigkeit auf Testdaten: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 14.45it/s, loss=0.153] \n",
      "Epoch 2: 100%|██████████| 89/89 [00:05<00:00, 14.83it/s, loss=0.0685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, Genauigkeit auf Testdaten: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 14.64it/s, loss=0.0473]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 14.53it/s, loss=0.021] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, Genauigkeit auf Testdaten: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 14.36it/s, loss=0.0767] \n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 13.57it/s, loss=0.0147] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, Genauigkeit auf Testdaten: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 14.75it/s, loss=0.00974]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 14.05it/s, loss=0.0106] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, Genauigkeit auf Testdaten: 0.71\n",
      "Genauigkeit mit Entropie-Unsicherheit: 0.72\n",
      "Genauigkeit mit Konfidenz-Unsicherheit: 0.71\n"
     ]
    }
   ],
   "source": [
    "def predict_uncertainty(model, data_loader):\n",
    "    model.eval()\n",
    "    uncertainties = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in data_loader:\n",
    "            images = images.unsqueeze(1)  # Dimension für den Kanal hinzufügen\n",
    "            outputs = model(images)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            entropy = -torch.sum(probabilities * torch.log(probabilities), dim=1)\n",
    "            uncertainties.extend(entropy.tolist())\n",
    "    return uncertainties\n",
    "\n",
    "def predict_confidence(model, data_loader):\n",
    "    model.eval()\n",
    "    confidences = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in data_loader:\n",
    "            images = images.unsqueeze(1)  # Dimension für den Kanal hinzufügen\n",
    "            outputs = model(images)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            max_confidence, _ = torch.max(probabilities, dim=1)\n",
    "            confidences.extend((1 - max_confidence).tolist())\n",
    "    return confidences\n",
    "\n",
    "def active_learning_cycle(unlabeled_loader_setting, train_loader, test_loader, criterion, optimizer, num_iterations=10, num_to_label=50, uncertainty_method=\"entropy\"):\n",
    "\n",
    "    model = SimpleCNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        \n",
    "        # Berechne Unsicherheiten\n",
    "        if uncertainty_method == \"entropy\":\n",
    "            uncertainties = predict_uncertainty(model, unlabeled_loader_setting)\n",
    "        elif uncertainty_method == \"confidence\":\n",
    "            uncertainties = predict_confidence(model, unlabeled_loader_setting)\n",
    "        else:\n",
    "            raise ValueError(\"Ungültige Uncertainty-Methode\")\n",
    "        \n",
    "        uncertain_indices = sorted(range(len(uncertainties)), key=lambda i: uncertainties[i], reverse=True)[:num_to_label]\n",
    "        \n",
    "        # Trainingsdaten mit gesampelten Daten kombinieren\n",
    "        new_images = torch.stack([unlabeled_loader_setting.dataset[i][0] for i in uncertain_indices])\n",
    "        new_labels = torch.tensor([unlabeled_loader_setting.dataset[i][1] for i in uncertain_indices])\n",
    "        combined_images = torch.cat((train_loader.dataset.tensors[0], new_images), dim=0)\n",
    "        combined_labels = torch.cat((train_loader.dataset.tensors[1], new_labels), dim=0)\n",
    "        combined_dataset = TensorDataset(combined_images, combined_labels)\n",
    "        combined_loader = DataLoader(combined_dataset, batch_size=64, shuffle=True)\n",
    "        \n",
    "        # Training\n",
    "        train(model, combined_loader, criterion, optimizer, epochs=2)\n",
    "        \n",
    "        # Eval.\n",
    "        test_accuracy = evaluate(model, test_loader)\n",
    "        print(f\"Iteration {iteration + 1}, Genauigkeit auf Testdaten: {test_accuracy:.2f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Uncertainty Sampling mit Entropie\n",
    "model_entropy = active_learning_cycle(unlabeled_loader, train_loader, test_loader, criterion, optimizer, uncertainty_method=\"entropy\")\n",
    "torch.save(model_entropy.state_dict(), 'uncertain_entropy_model.pth')\n",
    "\n",
    "# Uncertainty Sampling mit Konfidenzwerten\n",
    "model_confidence = active_learning_cycle(unlabeled_loader, train_loader, test_loader, criterion, optimizer, uncertainty_method=\"confidence\")\n",
    "torch.save(model_confidence.state_dict(), 'uncertain_confidence_model.pth')\n",
    "\n",
    "# Vergleich\n",
    "accuracy_entropy = evaluate(model_entropy, test_loader)\n",
    "accuracy_confidence = evaluate(model_confidence, test_loader)\n",
    "\n",
    "print(f\"Genauigkeit mit Entropie-Unsicherheit: {accuracy_entropy:.2f}\")\n",
    "print(f\"Genauigkeit mit Konfidenz-Unsicherheit: {accuracy_confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diversity sampling\n",
    "\n",
    "Methoden implementiert:\n",
    "\n",
    "1. Cluster-based Sampling\n",
    "\n",
    "2. Farthest-first Traversal (größter Abstand zwischen Merkmalen, berechnet mithilfe von `pairwise_distances`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 13.45it/s, loss=0.626]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 13.55it/s, loss=0.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Genauigkeit auf Testdaten: 0.6352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 13.47it/s, loss=0.578]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 13.92it/s, loss=0.513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, Genauigkeit auf Testdaten: 0.6944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 13.54it/s, loss=0.49] \n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 13.96it/s, loss=0.643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, Genauigkeit auf Testdaten: 0.7072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 13.37it/s, loss=0.449]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 14.06it/s, loss=0.381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, Genauigkeit auf Testdaten: 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 13.13it/s, loss=0.405]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 13.96it/s, loss=0.267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, Genauigkeit auf Testdaten: 0.7104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 13.61it/s, loss=0.191]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 13.72it/s, loss=0.142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, Genauigkeit auf Testdaten: 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:06<00:00, 13.39it/s, loss=0.2]   \n",
      "Epoch 2: 100%|██████████| 89/89 [00:07<00:00, 11.96it/s, loss=0.0907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, Genauigkeit auf Testdaten: 0.6704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:07<00:00, 12.36it/s, loss=0.0585]\n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 13.37it/s, loss=0.0764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, Genauigkeit auf Testdaten: 0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:07<00:00, 12.67it/s, loss=0.125] \n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 13.30it/s, loss=0.0508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, Genauigkeit auf Testdaten: 0.6704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 89/89 [00:07<00:00, 12.11it/s, loss=0.0253] \n",
      "Epoch 2: 100%|██████████| 89/89 [00:06<00:00, 13.16it/s, loss=0.0476] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, Genauigkeit auf Testdaten: 0.6976\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model_cluster\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiversity_cluster_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Diversity Sampling mit Farthest-first Traversal\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m model_farthest \u001b[38;5;241m=\u001b[39m \u001b[43mactive_learning_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43munlabeled_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiversity_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfarthest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model_farthest\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiversity_farthest_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Vergleich\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 50\u001b[0m, in \u001b[0;36mactive_learning_cycle\u001b[0;34m(unlabeled_loader_setting, train_loader, test_loader, criterion, optimizer, num_iterations, num_to_label, diversity_method)\u001b[0m\n\u001b[1;32m     48\u001b[0m     diverse_indices \u001b[38;5;241m=\u001b[39m diversity_sampling_cluster(model, unlabeled_loader_setting, num_to_label)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m diversity_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfarthest\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 50\u001b[0m     diverse_indices \u001b[38;5;241m=\u001b[39m \u001b[43mdiversity_sampling_farthest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlabeled_loader_setting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_to_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUngültige Diversity-Methode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 27\u001b[0m, in \u001b[0;36mdiversity_sampling_farthest\u001b[0;34m(model, unlabelled_loader, num_to_label)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, _ \u001b[38;5;129;01min\u001b[39;00m unlabelled_loader:\n\u001b[1;32m     26\u001b[0m         images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Dimension für den Kanal hinzufügen\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m         features\u001b[38;5;241m.\u001b[39mextend(outputs\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     30\u001b[0m diverse_indices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Startpunkt f. berechnung der distanzen\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/gan/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/gan/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m, in \u001b[0;36mSimpleCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[0;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n",
      "File \u001b[0;32m~/miniforge3/envs/gan/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/gan/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/gan/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/gan/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def diversity_sampling_cluster(model, unlabelled_loader, num_to_label):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in unlabelled_loader:\n",
    "            images = images.unsqueeze(1)  # Dimension für den Kanal hinzufügen\n",
    "            outputs = model(images)\n",
    "            features.extend(outputs.tolist())\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=num_to_label, random_state=0).fit(features)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    \n",
    "    diverse_indices = []\n",
    "    for center in cluster_centers:\n",
    "        distances = pairwise_distances([center], features)[0]\n",
    "        closest_index = distances.argmin()\n",
    "        diverse_indices.append(closest_index)\n",
    "    \n",
    "    return diverse_indices\n",
    "\n",
    "def diversity_sampling_farthest(model, unlabelled_loader, num_to_label):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in unlabelled_loader:\n",
    "            images = images.unsqueeze(1)  # Dimension für den Kanal hinzufügen\n",
    "            outputs = model(images)\n",
    "            features.extend(outputs.tolist())\n",
    "    \n",
    "    diverse_indices = [0]  # Startpunkt f. berechnung der distanzen\n",
    "    for _ in range(num_to_label - 1):\n",
    "        distances = pairwise_distances([features[diverse_indices[-1]]], features)[0]\n",
    "        farthest_index = distances.argmax()\n",
    "        diverse_indices.append(farthest_index)\n",
    "    \n",
    "    return diverse_indices\n",
    "\n",
    "def active_learning_cycle(unlabeled_loader_setting, train_loader, test_loader, criterion, optimizer, num_iterations=10, num_to_label=50, diversity_method=\"cluster\"):\n",
    "\n",
    "    model = SimpleCNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        \n",
    "        # Berechne Diversität\n",
    "        if diversity_method == \"cluster\":\n",
    "            diverse_indices = diversity_sampling_cluster(model, unlabeled_loader_setting, num_to_label)\n",
    "        elif diversity_method == \"farthest\":\n",
    "            diverse_indices = diversity_sampling_farthest(model, unlabeled_loader_setting, num_to_label)\n",
    "        else:\n",
    "            raise ValueError(\"Ungültige Diversity-Methode\")\n",
    "        \n",
    "        # Trainingsdaten mit gesampelten Daten kombinieren\n",
    "        new_images = torch.stack([unlabeled_loader_setting.dataset[i][0] for i in diverse_indices])\n",
    "        new_labels = torch.tensor([unlabeled_loader_setting.dataset[i][1] for i in diverse_indices])\n",
    "        \n",
    "        combined_images = torch.cat((train_loader.dataset.tensors[0], new_images), dim=0)\n",
    "        combined_labels = torch.cat((train_loader.dataset.tensors[1], new_labels), dim=0)\n",
    "        combined_dataset = TensorDataset(combined_images, combined_labels)\n",
    "        combined_loader = DataLoader(combined_dataset, batch_size=64, shuffle=True)\n",
    "        \n",
    "        # Training\n",
    "        train(model, combined_loader, criterion, optimizer, epochs=2)\n",
    "        \n",
    "        # Eval.\n",
    "        test_accuracy = evaluate(model, test_loader)\n",
    "        print(f\"Iteration {iteration + 1}, Genauigkeit auf Testdaten: {test_accuracy}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Diversity Sampling mit Cluster-based Sampling\n",
    "model_cluster = active_learning_cycle(unlabeled_loader, train_loader, test_loader, criterion, optimizer, diversity_method=\"cluster\")\n",
    "torch.save(model_cluster.state_dict(), 'diversity_cluster_model.pth')\n",
    "\n",
    "# Diversity Sampling mit Farthest-first Traversal\n",
    "model_farthest = active_learning_cycle(unlabeled_loader, train_loader, test_loader, criterion, optimizer, diversity_method=\"farthest\")\n",
    "torch.save(model_farthest.state_dict(), 'diversity_farthest_model.pth')\n",
    "\n",
    "# Vergleich\n",
    "accuracy_cluster = evaluate(model_cluster, test_loader)\n",
    "accuracy_farthest = evaluate(model_farthest, test_loader)\n",
    "\n",
    "print(f\"Genauigkeit mit Cluster-based Sampling: {accuracy_cluster}\")\n",
    "print(f\"Genauigkeit mit Farthest-first Traversal: {accuracy_farthest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleiche die Genauigkeiten aller Methoden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Genauigkeit ohne Active Learning: {test_accuracy}\")\n",
    "print(f\"Genauigkeit mit Entropie-Unsicherheit: {accuracy_entropy}\")\n",
    "print(f\"Genauigkeit mit Konfidenz-Unsicherheit: {accuracy_confidence}\")\n",
    "print(f\"Genauigkeit mit Cluster-based Sampling: {accuracy_cluster}\")\n",
    "print(f\"Genauigkeit mit Farthest-first Traversal: {accuracy_farthest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manuelle daten labelung \n",
    ".. aus dem ersten Versuch - hab dann bestehende labels genutzt weil Zeit :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image, ImageOps\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader, Subset\n",
    "# import pandas as pd\n",
    "# from torchvision import transforms\n",
    "# from IPython.display import display, clear_output\n",
    "# \n",
    "# # Funktion zur manuellen Beschriftung der Bilder mit größerer Bildanzeige\n",
    "# def manual_labeling(data_loader, indices):\n",
    "#     # Leeres DataFrame für gelabelte Daten\n",
    "#     labeled_data = pd.DataFrame(columns=['label'])\n",
    "# \n",
    "#     for i, (images, _) in enumerate(data_loader):\n",
    "#         img = transforms.ToPILImage()(images.squeeze(0))\n",
    "#         img = img.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "#         display(img)  # Verwende display anstatt img.show()\n",
    "#         label = input(\"Label eingeben (0 für Katze, 1 für Hund): \")\n",
    "#         clear_output(wait=True)\n",
    "#         labeled_data.loc[i] = [int(label)]\n",
    "# \n",
    "#     return labeled_data\n",
    "# \n",
    "# # Bereite den DataLoader vor, der nur die unsicheren Daten enthält\n",
    "# uncertain_data_loader = Subset(ungelabeled_loader.dataset, uncertain_indices)\n",
    "# uncertain_loader = DataLoader(uncertain_data_loader, batch_size=1, shuffle=False)\n",
    "# \n",
    "# # Labeln der unsicheren Daten manuell\n",
    "# labeled_uncertain_data = manual_labeling(uncertain_loader, uncertain_indices)\n",
    "# labeled_uncertain_data.to_csv('labeled_uncertain_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
